{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxgKxSHFMRLQiPdmFdJSy0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nnilayy/Model-Quantization/blob/main/Model_Quantization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "esJE2uN6zlsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8n7AXkkmbg6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def get_file_size(file_path):\n",
        "  size=os.path.getsize(file_path)\n",
        "  return size"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_bytes(size,unit=None):\n",
        "  if unit==\"KB\":\n",
        "    return print(\"File size: \"+str(round(size/1024,3))+\" Kilobytes\")\n",
        "  elif unit==\"MB\":\n",
        "    return print(\"File size: \"+str(round(size/(1024*1024),3))+\" Megabytes\")\n",
        "  else:\n",
        "    return print(\"File size: \"+str(size)+\"bytes\")"
      ],
      "metadata": {
        "id": "CwszOo31rBJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TFLite Model"
      ],
      "metadata": {
        "id": "cD6d97txukdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=\"/content/drive/MyDrive/Unet_weights/31_Mil.h5\""
      ],
      "metadata": {
        "id": "55apsonRENr_"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Size Before Model Quantization\n",
        "convert_bytes(get_file_size(model),\"MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5731ef9c-ef5d-4261-b9d6-4e32e63d5f7c",
        "id": "g4S-i8RKD8vG"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File size: 237.238 Megabytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "model=tf.keras.models.load_model(model)\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "# Default Optimization\n",
        "converter.optimizations=[tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# Optimization For Best Size\n",
        "# converter.optimizations=[tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "\n",
        "# To a specific type of value optimization \n",
        "# converter.target_spec.supported_types=[tf.int16]\n",
        "converter.experimental_new_converter = True\n",
        "tflite_model_name=\"def_opt_model.tflite\"\n",
        "tflite_model = converter.convert()\n",
        "open(tflite_model_name,\"wb\").write(tflite_model)"
      ],
      "metadata": {
        "id": "4sPioRvD91WU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Size After Model Quantization\n",
        "tflite_model=\"/content/drive/MyDrive/Unet_weights/def_opt_model.tflite\"\n",
        "convert_bytes(get_file_size(tflite_model),\"MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K368QGNq-_MV",
        "outputId": "308e5683-4cc9-4f75-beb4-843500b44f98"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File size: 29.712 Megabytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.youtube.com/watch?v=IuyTC-_otGw\n",
        "# https://www.youtube.com/watch?v=HXzz87WVm6c\n",
        "# https://www.youtube.com/watch?v=VPY7Itw6aiA"
      ],
      "metadata": {
        "id": "eYrGvhfH15O-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Increasing Accuracy of Model"
      ],
      "metadata": {
        "id": "LRURHwir79mD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Pretrained Convolutional Layers \n",
        "# Better Variant Dataset "
      ],
      "metadata": {
        "id": "cuwa66bJ78xG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reducing Model Size: Model Pruning "
      ],
      "metadata": {
        "id": "nDpry18hDZSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras\n",
        "# https://medium.com/analytics-vidhya/reducing-deep-learning-model-size-without-effecting-its-original-performance-and-accuracy-with-a809b49cf519"
      ],
      "metadata": {
        "id": "pIKBU20wDdkF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}